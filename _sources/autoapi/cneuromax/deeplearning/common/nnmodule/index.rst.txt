:py:mod:`cneuromax.deeplearning.common.nnmodule`
================================================

.. py:module:: cneuromax.deeplearning.common.nnmodule

.. autoapi-nested-parse::

   .



Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   mlp/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   cneuromax.deeplearning.common.nnmodule.MLP
   cneuromax.deeplearning.common.nnmodule.MLPConfig




.. py:class:: MLP(config: MLPConfig, activation_fn: torch.nn.Module)


   Bases: :py:obj:`torch.nn.Module`

   Multi-layer perceptron (MLP).

   Allows for a variable number of layers, activation functions, and
   dropout probability.

   .. attribute:: model

      The MLP model.

   Calls parent constructor, initializes model.

   :param config: .
   :param activation_fn: .

   .. py:method:: forward(x: jaxtyping.Float[torch.Tensor,  batch_size *d_input]) -> jaxtyping.Float[torch.Tensor,  batch_size output_size]

      Flattens input dimensions and pass through the model.

      .. note::

         This MLP isn't (yet?) suitable for cases where the output is
         multidimensional.

      :param x: .

      :returns: The output vector batch.



.. py:class:: MLPConfig


   .

   .. attribute:: dims

      List of dimensions for each layer.

   .. attribute:: p_dropout

      Dropout probability.

   .. py:attribute:: dims
      :type: list[cneuromax.common.utils.annotations.int_is_gt0] | tuple[cneuromax.common.utils.annotations.int_is_gt0]

      

   .. py:attribute:: p_dropout
      :type: cneuromax.common.utils.annotations.float_is_ge0_le1

      


